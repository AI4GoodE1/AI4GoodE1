{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Libraries needed for NLP\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_df = df = pd.read_csv('fraud_email_cleaned_no_dups.csv')\n",
    "sms_df = pd.read_csv('dataset/sms_cleaned_no_dups.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "email: 10249\n",
      "sms: 5171\n"
     ]
    }
   ],
   "source": [
    "#check len\n",
    "print(\"email:\",len(email_df))\n",
    "print(\"sms:\",len(sms_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15420"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.merge(email_df,sms_df, how='outer')\n",
    "len(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Text, Class]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for NaN values in data\n",
    "df1 = merged_df[merged_df.isna().any(axis=1)]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 15420\n",
      "Unique: 15420\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in data\n",
    "print(\"Total: \" + str(len(merged_df)))\n",
    "print(\"Unique: \" + str(merged_df[\"Text\"].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export cleaned dataset to csv\n",
    "merged_df.to_csv('dataset/merged_dataset_cleaned.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/merged_dataset_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\shane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\shane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\shane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "C:\\Users\\shane\\AppData\\Local\\Temp\\ipykernel_36472\\297871604.py:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Text'] = df['Text'].str.replace(r'(<?)([A-Za-z0-9.]{1,30})@([A-Za-z0-9.]{1,30}).([a-z]{2,3})(>?)', 'emailaddress')\n",
      "C:\\Users\\shane\\AppData\\Local\\Temp\\ipykernel_36472\\297871604.py:14: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Text'] = df['Text'].str.replace(r\"(https?:)(.?)(([^\\s]+)|$)|(www.)(.?)(([^\\s]+)|$)|(news.)(.*?)(([^\\s]+)|$)\", 'webaddress')\n",
      "C:\\Users\\shane\\AppData\\Local\\Temp\\ipykernel_36472\\297871604.py:17: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Text'] = df['Text'].str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$', 'phone-number')\n",
      "C:\\Users\\shane\\AppData\\Local\\Temp\\ipykernel_36472\\297871604.py:20: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Text'] = df['Text'].str.replace(r'\\d+(\\.\\d+)?', 'number')\n",
      "C:\\Users\\shane\\AppData\\Local\\Temp\\ipykernel_36472\\297871604.py:23: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Text'] = df['Text'].str.replace(r'(qzsoft)(\\S+)', ' qzsoft')\n",
      "C:\\Users\\shane\\AppData\\Local\\Temp\\ipykernel_36472\\297871604.py:26: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Text'] = df['Text'].str.replace(r'([\\S]{250,})', 'brokenmime')\n",
      "C:\\Users\\shane\\AppData\\Local\\Temp\\ipykernel_36472\\297871604.py:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Text'] = df['Text'].str.replace(r'\\s+', ' ')\n",
      "C:\\Users\\shane\\AppData\\Local\\Temp\\ipykernel_36472\\297871604.py:32: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Text'] = df['Text'].str.replace(r'^\\s+|\\s*?$', ' ')\n",
      "C:\\Users\\shane\\AppData\\Local\\Temp\\ipykernel_36472\\297871604.py:35: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Text'] = df['Text'].str.replace(r\"<(\\\"[^\\\"]*\\\"|'[^']*'|[^'\\\">])*>\", ' formatting ')\n",
      "C:\\Users\\shane\\AppData\\Local\\Temp\\ipykernel_36472\\297871604.py:36: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Text'] = df['Text'].str.replace(r\"(&nbsp;)\", ' formatting ')\n",
      "C:\\Users\\shane\\AppData\\Local\\Temp\\ipykernel_36472\\297871604.py:38: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Text'] = df['Text'].str.replace(r\"[_]{1,}\", 'blankLines')\n",
      "C:\\Users\\shane\\AppData\\Local\\Temp\\ipykernel_36472\\297871604.py:41: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Text'] = df['Text'].str.replace(r'[^\\w\\d\\s]', ' ')\n"
     ]
    }
   ],
   "source": [
    "# Stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# Lemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "lemmatizer = WordNetLemmatizer()# Cleanup\n",
    "\n",
    "# replace email address with 'emailaddress'\n",
    "df['Text'] = df['Text'].str.replace(r'(<?)([A-Za-z0-9.]{1,30})@([A-Za-z0-9.]{1,30}).([a-z]{2,3})(>?)', 'emailaddress')\n",
    "\n",
    "# replace urls with 'webaddress'\n",
    "df['Text'] = df['Text'].str.replace(r\"(https?:)(.?)(([^\\s]+)|$)|(www.)(.?)(([^\\s]+)|$)|(news.)(.*?)(([^\\s]+)|$)\", 'webaddress')\n",
    "\n",
    "# replace 10 digit phone number with 'phone-number'\n",
    "df['Text'] = df['Text'].str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$', 'phone-number')\n",
    "\n",
    "# replace normal number with 'number'\n",
    "df['Text'] = df['Text'].str.replace(r'\\d+(\\.\\d+)?', 'number')\n",
    "\n",
    "# replace qzsoft strings\n",
    "df['Text'] = df['Text'].str.replace(r'(qzsoft)(\\S+)', ' qzsoft')\n",
    "\n",
    "# replace broken MIME\n",
    "df['Text'] = df['Text'].str.replace(r'([\\S]{250,})', 'brokenmime')\n",
    "\n",
    "# remove whitespace between terms with single space\n",
    "df['Text'] = df['Text'].str.replace(r'\\s+', ' ')\n",
    "\n",
    "# remove leading and trailing whitespace\n",
    "df['Text'] = df['Text'].str.replace(r'^\\s+|\\s*?$', ' ')\n",
    "\n",
    "# # replace html tags with 'format'\n",
    "df['Text'] = df['Text'].str.replace(r\"<(\\\"[^\\\"]*\\\"|'[^']*'|[^'\\\">])*>\", ' formatting ')\n",
    "df['Text'] = df['Text'].str.replace(r\"(&nbsp;)\", ' formatting ')\n",
    "\n",
    "df['Text'] = df['Text'].str.replace(r\"[_]{1,}\", 'blankLines')\n",
    "\n",
    "# remove punctuation\n",
    "df['Text'] = df['Text'].str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "\n",
    "# change words to lower case\n",
    "df['Text'] = df['Text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying English Stopwords\n",
    "df['Text'] = df['Text'].apply(lambda x: ' '.join(term for term in x.split() if term not in stop_words))\n",
    "# Applying Wordnet Lemmatizer\n",
    "df['Text'] = df['Text'].apply(lambda x: ' '.join(lemmatizer.lemmatize(term) for term in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention numbera president numberfdirector numberc chairman contract award committee gold natural resource ministry dakar senegal numberc security reason numberc may wish disclose important thing hear numbere due deliberation partner numberc decided forward business proposal numberc want assist u receive sum twenty million united state bill account numbere fund resulted invoiced contract awarded u budget allocation ministry bill approved payment concerned ministry numbere contract executed numberc commissioned contractor paid actual cost contract numbere numberc left balance twenty million dollar invoiced amount numberc deliberately estimated use numbere please note law forbids civil servant operate foreign account hence contact numberc agreed share money following percentage numbera number numberc number u number tax may required government numberc numberft need anything delay money arrive bank account numbere note transaction much free sort risk hence business carefully planned successfully executed official involved deal put many year service ministry numbere exercising patience privilege long presidential announcement last week numberc foreign contractor owed paid forthwith numberc enable presidency reconcile debt ratio outside world u numberc lifetime blessing cannot afford miss numbere upon indication interest fully co operate u numberc payment application numberfinformation form sent via email completion numbere note following information numbera private phone number email address willenable u seek numberfsecure approval fund concerned government quarter numberfministries within number number banking day numbere soon confirm receipt money nominated bank account numberc partner come country arrange share possibly invest part money country numbere let honesty trust watchword throughout transaction numbere shall furnish detail numbere prompt reply highly appreciated numbere best regard numbereengr numbere phiri aboa\n",
      "1\n",
      "-----------------------------------------------------------\n",
      "\n",
      "mill cheryl emailaddresssaturday may number number number number amhis monday better bnumber\n",
      "0\n",
      "-----------------------------------------------------------\n",
      "\n",
      "class lt gt reunion\n",
      "0\n",
      "-----------------------------------------------------------\n",
      "\n",
      "r mr habib waheed date number number number kindest attention numbermy name mr habib waheed dubai diagnosed numberesophageal cancer defiled form medical treatment rig ht numbernow month live according medical expert numberhave particularly lived life well never really cared numberanyone even business though rich nev er numbergenerous always hostile people focused business numberthat thing cared numberbut regret know life j ust numberwanting make money world believe god gi f numberme second chance come world would live life different numberway lived numbernow god called willed given property nd numberassets immediate extended family member well close numberfriends want god merciful accept soul numberdecided give alms charity organization need wan numberthis one last good deed earth numberso far distributed money charity organization numberwell health deteriorated badly cannot myse lf numberanymore asked member family close one account numberdistribute money charity organization united numberstates asia middle east europe refused kept money numberthemselves numberhence trust anymore seem contended numberwhat left last money one know numberhuge cash deposit ten million united state dollar number number number asset management vaulting company abroad numberwill want help collect deposit dispatch charity numberorganizations use help need numbern b kindly note number fund must go victim tsunami numberhurricane katrina hurricane wilma south asia earthquake number ot numbercharity organization around world number effort time cannot talk phone due health situation numberusing lap top computer communicate respond numberthis e mail interested carrying assignment numberbehalf numbergod mr habib emailaddress habib waheed\n",
      "1\n",
      "-----------------------------------------------------------\n",
      "\n",
      "would like blackberry rev dr bill shillady shill uh dee united methodist city societyexecutive director\n",
      "0\n",
      "-----------------------------------------------------------\n",
      "\n",
      "take numberpm shuttle u want still press move tuesday also think canclear schedule tomorrow move thing rest week u stay fly afternoon meeting fm armenianumber numberpm meeting joe kleinnumber numberpmnumber numberpm meeting david ignatiusnumber numberpmnumber numberpm brief meeting jim smithnumber numberpm saudi amb choice number numberpmbrief meeting steve radelet mcc choice number numberpmnumber numberpm meeting shimon peres saying go state may move tuesday\n",
      "0\n",
      "-----------------------------------------------------------\n",
      "\n",
      "maybe want know obviously tbd happy new year clinton number bnumberrelease partbnumber\n",
      "0\n",
      "-----------------------------------------------------------\n",
      "\n",
      "hillary met holbrooke today water pakistani military called third important strategic issue greatworries india pakistan tension number agreement regulates indus river agreed team worktogether likely world bank supporting abu dhabi dialogue brings together representativesfrom seven country share indus river basin best forum know india pakistancan meet discus water issue context shared water memo chart gave last week rank aspotentially one conflict prone one u engage get party work together advancing well developing policy action plan announce world water day march number safe travel latin america glad going mariaunder secretary statefor democracy global affairsdepartment statenumber c st nw room numberwashington dc number number number\n",
      "0\n",
      "-----------------------------------------------------------\n",
      "\n",
      "late said website dont slipper\n",
      "0\n",
      "-----------------------------------------------------------\n",
      "\n",
      "exhausted train morning much wine pie sleep well\n",
      "0\n",
      "-----------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random sampling of data to investigate dataset\n",
    "for i in range(0,10):\n",
    "  v = df.sample()\n",
    "  # print(v.iloc[0])\n",
    "  print(v.iloc[0][\"Text\"])\n",
    "  print(v.iloc[0][\"Class\"])\n",
    "  print(\"-----------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15420"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export\n",
    "# Export cleaned dataset to csv\n",
    "df.to_csv('dataset/merged_dataset_preprocessed.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bb43443fa454556f18816e979c43a6320d4342298f866d13f108c6970b0d4f17"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('AI4Goodlab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
